{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1hL_bf9aUqeS7grCc3APj_rmriIUFVerA",
      "authorship_tag": "ABX9TyNk1F1Px4K8SJcUYTEGBkg+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OLAMILEKAN011/LLM/blob/main/Project_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKDMI5o46P1n"
      },
      "outputs": [],
      "source": [
        "# Install OpenAI\n",
        "!pip install OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Pinecone-client for embedding storage\n",
        "!pip install pinecone-client"
      ],
      "metadata": {
        "id": "sBI67Lq1M__-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Install tiktoken\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "p7ImSj35Ncit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install langchain\n",
        "!pip install langchain"
      ],
      "metadata": {
        "id": "eIiLmukM_yQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install chromadb for vector database storage\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "D-Iz_Fz5AFCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting API_KEYS, Model and Environment\n",
        "\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"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\"\n",
        "OPEN_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "import nltk\n",
        "\n",
        "#embed_model = \"text-davinci-002\"\n",
        "\n",
        "embed_model = \"gpt-4\"\n",
        "\n",
        "#embed_model = \"gpt-4-32k\"\n",
        "\n",
        "\n",
        "os.environ[\"PINECONE_API_KEY\"] = \"83c81792-7df9-458c-8bb1-d0f2e438fd84\"\n",
        "PINECONE_API_KEY = os.environ[\"PINECONE_API_KEY\"]\n",
        "PINECONE_ENV = \"northamerica-northeast1-gcp\"\n",
        "\n"
      ],
      "metadata": {
        "id": "bnolC_CgP4Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install llama index for document indexing\n",
        "!pip install pydantic -U\n",
        "!pip install llama_index"
      ],
      "metadata": {
        "id": "H9zX2cfVBZ5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install unstructured to process unstructured data\n",
        "!pip install unstructured"
      ],
      "metadata": {
        "id": "Dkx7PzfiEPm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required modules\n",
        "\n",
        "import openai\n",
        "import pinecone\n",
        "import langchain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain import VectorDBQA\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.document_loaders import DirectoryLoader\n"
      ],
      "metadata": {
        "id": "OCPntCxF96CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J7CkX7zTBbvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries and Loading data into 'documents'\n",
        "\n",
        "from pathlib import Path\n",
        "import llama_index\n",
        "from llama_index import download_loader\n",
        "\n",
        "# To ingest documents\n",
        "\n",
        "PDFReader = download_loader(\"PDFReader\")\n",
        "\n",
        "loader = PDFReader()\n",
        "documents = loader.load_data(file=Path('/content/drive/MyDrive/Colab Notebooks/New Extra document.pdf'))"
      ],
      "metadata": {
        "id": "p25i9b9wAdYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3lk27f6bWJoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To view the content of document ingested\n",
        "documents"
      ],
      "metadata": {
        "id": "HDDdelOwAkXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the RecursiveCharacterTextSpliter\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000,chunk_overlap = 0, length_function = len,)\n",
        "texts = [doc.text for doc in documents]\n",
        "\n",
        "# Split document content\n",
        "texts = text_splitter.create_documents(texts)\n",
        "\n"
      ],
      "metadata": {
        "id": "YDTXiMiAX7AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#doc_texts = text_splitter.create_documents([documents])\n",
        "#print(len(doc_texts))\n",
        "#type(doc_texts)"
      ],
      "metadata": {
        "id": "SoatXyRgXtTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print total number of document chunk and check type\n",
        "\n",
        "print(len(texts))\n",
        "type(texts)"
      ],
      "metadata": {
        "id": "zhgLuj_LZGTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View a particular chunk of the entire document\n",
        "\n",
        "texts[2]"
      ],
      "metadata": {
        "id": "tPj14LG8ZG93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#texts = [doc.text for doc in documents]\n",
        "#split_texts = text_splitter.split_documents(texts)"
      ],
      "metadata": {
        "id": "RpMydjciZGe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pinecone and OpenAI Embedding Set up\n",
        "\n",
        "pinecone.init(\n",
        "        api_key = PINECONE_API_KEY,\n",
        "        environment= PINECONE_ENV\n",
        ")\n",
        "\n",
        "# Index name already set up in Pinecone page\n",
        "index_name = \"project\""
      ],
      "metadata": {
        "id": "Nhb9F9sDaFZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key = OPEN_API_KEY)"
      ],
      "metadata": {
        "id": "ZQIvVlV5aFQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vector database\n",
        "\n",
        "if index_name not in pinecone.list_indexes():\n",
        "  print(\"Index does not exist: \", index_name)\n",
        "\n",
        "doc_docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name = index_name)"
      ],
      "metadata": {
        "id": "80fYO3MZeH_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(doc_docsearch)"
      ],
      "metadata": {
        "id": "buBM8G56e5ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import load_QA_chain\n",
        "\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ],
      "metadata": {
        "id": "dZWNxwhyixdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up query model\n",
        "\n",
        "llm = OpenAI(temperature=0.8, openai_api_key= OPEN_API_KEY)"
      ],
      "metadata": {
        "id": "Kb7SGE0TixaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up query\n",
        "\n",
        "#question = \"in about 500 words, What are the laws guiding conduct of the players?\"\n",
        "#qsearch = doc_docsearch.similarity_search(question)"
      ],
      "metadata": {
        "id": "ujxDzMlXixWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up response generator\n",
        "\n",
        "#chain = load_qa_chain(llm, chain_type= \"stuff\")\n",
        "#chain.run(input_documents = qsearch, question = question)"
      ],
      "metadata": {
        "id": "rRZqD2KkixSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "# Creating chat memory\n",
        "\n",
        "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature = 0.8), doc_docsearch.as_retriever())"
      ],
      "metadata": {
        "id": "fntPVR9wKu1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "import ipywidgets as widgets"
      ],
      "metadata": {
        "id": "Kp9C4zGrQfPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "\n",
        "def on_submit(_):\n",
        "  query = input_box.value\n",
        "  input_box.value = \" \"\n",
        "\n",
        "  if query.lower() == 'exit':\n",
        "    print(\"Thank you for using My Project Chatbot!\")\n",
        "    return\n",
        "\n",
        "  result = qa({\"question\": query, \"chat_history\": chat_history})\n",
        "  chat_history.append((query, result['answer']))\n",
        "\n",
        "  display(widgets.HTML(f'<b>Query:</b> {query}'))\n",
        "  display(widgets.HTML(f'<b><font color=\"blue\">Response:</font></b> {result[\"answer\"]}'))\n",
        "\n",
        "print(\"Welcome to My Project Chatbot! Type 'exit' to stop.\")\n",
        "\n",
        "input_box = widgets.Text(placeholder = 'Please enter your question:')\n",
        "input_box.on_submit(on_submit)\n",
        "\n",
        "display(input_box)"
      ],
      "metadata": {
        "id": "ivuH5qH7KujE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DirFTujglr2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "def on_submit(_):\n",
        "    query = input_box.value\n",
        "    input_box.value = ''\n",
        "\n",
        "    if query.lower() == 'exit':\n",
        "        print(\"Thank you for using My Project Chatbot!\")\n",
        "        return\n",
        "\n",
        "    result = qa({\"question\": query, \"chat_history\": chat_history})\n",
        "    chat_history.append((query, result['answer']))\n",
        "\n",
        "    query_display = widgets.HTML(f'<b>Query:</b> {query}')\n",
        "    response_display = widgets.HTML(f'<b><font color=\"blue\">Response:</font></b> {result[\"answer\"]}')\n",
        "\n",
        "    response_length = len(result[\"answer\"])\n",
        "    length_display = widgets.HTML(f'<b>Response Length:</b> {response_length}')\n",
        "\n",
        "    display(query_display)\n",
        "    display(response_display)\n",
        "    display(length_display)\n",
        "\n",
        "print(\"Welcome to My Project Chatbot! Type 'exit' to stop.\")\n",
        "\n",
        "input_box = widgets.Text(placeholder='Please enter your question:')\n",
        "input_box.on_submit(on_submit)\n",
        "\n",
        "display(input_box)\n",
        "\n"
      ],
      "metadata": {
        "id": "7cO3cR3bls4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "def generate_response(query, max_words):\n",
        "    result = qa({\"question\": query, \"chat_history\": chat_history})\n",
        "    chat_history.append((query, result['answer']))\n",
        "\n",
        "    response_words = result[\"answer\"].split()\n",
        "    truncated_response = ' '.join(response_words[:max_words])\n",
        "    return truncated_response\n",
        "\n",
        "def on_submit(_):\n",
        "    query = input_box.value\n",
        "    input_box.value = ''\n",
        "\n",
        "    if query.lower() == 'exit':\n",
        "        print(\"Thank you for using My Project Chatbot!\")\n",
        "        return\n",
        "\n",
        "    response_length = int(response_length_input.value)\n",
        "    truncated_response = generate_response(query, response_length)\n",
        "\n",
        "    query_display = widgets.HTML(f'<b>Query:</b> {query}')\n",
        "    response_display = widgets.HTML(f'<b><font color=\"blue\">Response:</font></b> {truncated_response}')\n",
        "    length_display = widgets.HTML(f'<b>Response Length:</b> {response_length} words')\n",
        "\n",
        "    display(query_display)\n",
        "    display(response_display)\n",
        "    display(length_display)\n",
        "\n",
        "print(\"Welcome to My Project Chatbot! Type 'exit' to stop.\")\n",
        "\n",
        "input_box = widgets.Text(placeholder='Please enter your question:')\n",
        "input_box.on_submit(on_submit)\n",
        "\n",
        "response_length_input = widgets.IntSlider(min=1, max=100, value=20, description='Response Length (words):')\n",
        "display(input_box)\n",
        "display(response_length_input)\n"
      ],
      "metadata": {
        "id": "ECSsCkFdKue2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"END!\")"
      ],
      "metadata": {
        "id": "X5QRPBR-Kuam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TptEy1N0KuKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jhu-uP6_OOLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bazYm82NON9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LIcgg9jEON5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7-GNu0x4ixNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tQ9mH4JpuL18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r3meMjhwuLxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sbISiXICIhEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_2x0mMtrMXfg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}